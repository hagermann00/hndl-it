# hndl-it Context Document

## Version 5.6 | January 2026

---

## ğŸ¯ What is hndl-it?

**hndl-it** is a local-first, Windows-native agentic system that lets you control your computer through natural language. It uses local LLMs (via Ollama) for semantic understanding and routes commands to specialized agents.

> *"Say it, and consider it handled."*

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SUPERVISOR.PY                          â”‚
â”‚                (Singleton Process Manager)                   â”‚
â”‚            - PID lock file prevents duplicates               â”‚
â”‚            - Tree-kill ensures clean shutdown                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LAUNCH_SUITE.PY                          â”‚
â”‚               (Unified UI + Agent Launcher)                  â”‚
â”‚                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚hndl-it â”‚ â”‚read-it â”‚ â”‚todo-it â”‚ â”‚voice-itâ”‚               â”‚
â”‚   â”‚  ğŸ¯    â”‚ â”‚  ğŸ“–    â”‚ â”‚  âœ…    â”‚ â”‚  ğŸ¤    â”‚               â”‚
â”‚   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜               â”‚
â”‚       â”‚          â”‚          â”‚          â”‚                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                       â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR                               â”‚
â”‚              (shared/orchestrator.py)                         â”‚
â”‚                                                               â”‚
â”‚   Tier 1: Regex Fast-Path (0ms)                              â”‚
â”‚           â””â”€ Pattern matching for common commands             â”‚
â”‚                                                               â”‚
â”‚   Tier 2: LLM Router (Gemma 2B, ~200ms)                      â”‚
â”‚           â””â”€ Semantic classification for ambiguous input      â”‚
â”‚                                                               â”‚
â”‚   Output: Structured Intent â†’ IPC                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ File-based IPC (ipc/*.json)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       AGENTS                                  â”‚
â”‚                                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚ Browser  â”‚ â”‚ Desktop  â”‚ â”‚   Read   â”‚ â”‚  Vision  â”‚       â”‚
â”‚   â”‚   ğŸŒ     â”‚ â”‚   ğŸ–¥ï¸     â”‚ â”‚   ğŸ”Š     â”‚ â”‚   ğŸ‘ï¸     â”‚       â”‚
â”‚   â”‚   CDP    â”‚ â”‚ pyauto   â”‚ â”‚   TTS    â”‚ â”‚ moondream â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  LLM Configuration

Located in `shared/llm_config.py`. Using "Two-Gear" strategy:

| Role | Model | VRAM | Purpose |
|------|-------|------|---------|
| **Router** | gemma2:2b | ~1.6 GB | Fast intent classification (always resident) |
| **Brain** | qwen2.5:3b | ~2.0 GB | Complex reasoning (on-demand) |
| **Vision** | moondream | ~1.7 GB | Image understanding (on-demand) |

**Total VRAM**: ~5.3 GB base, ~7.5 GB with overhead  
**Hardware**: RTX 2060 12GB â†’ 4.5 GB headroom âœ…

---

## ğŸ“ Project Structure

```
hndl-it/
â”œâ”€â”€ supervisor.py          # Singleton launcher with process tree management
â”œâ”€â”€ launch_suite.py        # Unified icon manager + agent starter
â”œâ”€â”€ warm_models.py         # Force-load LLMs into VRAM
â”œâ”€â”€ launch_agents.py       # Standalone agent launcher
â”‚
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ orchestrator.py    # Semantic command router (Gemma 2B)
â”‚   â”œâ”€â”€ ipc.py             # File-based inter-process communication
â”‚   â”œâ”€â”€ llm_config.py      # Model configuration + VRAM validation
â”‚   â”œâ”€â”€ voice_input.py     # Global hotkey + speech recognition
â”‚   â””â”€â”€ voice_router.py    # Keyword-based voice routing
â”‚
â”œâ”€â”€ floater/               # Main UI module
â”‚   â”œâ”€â”€ tray.py            # System tray + command handling
â”‚   â”œâ”€â”€ quick_dialog.py    # Command input bar (multiple modes)
â”‚   â”œâ”€â”€ console.py         # Log console window
â”‚   â””â”€â”€ assets/            # Icons
â”‚
â”œâ”€â”€ read-it/               # TTS reader module
â”‚   â”œâ”€â”€ main.py            # Reader panel + selection pill
â”‚   â””â”€â”€ ipc_handler.py     # TTS IPC listener
â”‚
â”œâ”€â”€ todo-it/               # Task manager module
â”‚   â”œâ”€â”€ main.py            # Todo panel with persistence
â”‚   â””â”€â”€ todos.json         # Saved tasks (auto-persisted)
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ browser/
â”‚   â”‚   â”œâ”€â”€ server.py          # WebSocket server (port 8766)
â”‚   â”‚   â”œâ”€â”€ browser_controller.py  # Chrome CDP automation
â”‚   â”‚   â””â”€â”€ ipc_handler.py     # IPC-based browser control
â”‚   â”œâ”€â”€ desktop/
â”‚   â”‚   â”œâ”€â”€ server.py          # WebSocket server (port 8767)
â”‚   â”‚   â””â”€â”€ ipc_handler.py     # pyautogui automation
â”‚   â””â”€â”€ vision/                # Moondream image analysis (scaffold)
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_orchestrator.py   # Routing validation (13.5/14 pass)
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ MASTER_SYNTHESIS.md    # Multi-LLM strategic roadmap
    â”œâ”€â”€ MEM_RESEARCH_INTEGRATION.md  # Airweave + NotebookLM plans
    â””â”€â”€ TODO.md                # Development backlog
```

---

## ğŸ® Command Examples

### Regex Fast-Path (0ms)

| Command | Target | Action |
|---------|--------|--------|
| `go to reddit.com` | browser | navigate |
| `search cheap GPUs on ebay` | browser | search_site |
| `add buy milk` | todo | add |
| `read this to me` | read | speak |
| `type hello world` | desktop | type |
| `screenshot` | desktop | screenshot |

### LLM Router (Gemma 2B, ~200ms)

| Command | Target | Action |
|---------|--------|--------|
| `find the cheapest flight to Paris` | browser | search |
| `what did I work on yesterday?` | retrieval | search |
| `analyze this PDF` | research | upload |

---

## ğŸ”Œ Communication

### IPC (Inter-Process Communication)

File-based messaging in `ipc/` directory:

```python
from shared.ipc import send_command, check_mailbox

# Send command to agent
send_command("browser", "navigate", {"url": "https://reddit.com"})

# Agent checks for commands
action, payload = check_mailbox("browser")
```

### WebSocket (Legacy)

Original agent servers on dedicated ports:

- Browser: `ws://localhost:8766`
- Desktop: `ws://localhost:8767`
- Vision: `ws://localhost:8768`

---

## ğŸš€ Quick Start

```powershell
# 1. Warm up LLMs (first run or after reboot)
python warm_models.py

# 2. Launch the suite
python supervisor.py

# 3. Interact
# - Click icons to toggle panels
# - Type commands in input bar
# - Ctrl+Shift+Win for voice input
# - Right-click any icon for context menu
```

---

## ğŸ¯ Voice Hotkeys

| Hotkey | Action |
|--------|--------|
| `Ctrl+Shift+Win` | Toggle voice input (start/stop) |
| `Ctrl+Win+Alt` | Windows native dictation (Win+H) |

---

## ğŸ“Š Status Indicators

The 3 dots in the input bar show agent status:

- âš« Gray = Offline
- ğŸŸ¢ Green = Connected + Idle
- ğŸ’š Pulsing = Working
- ğŸŸ¡ Yellow = Trouble
- ğŸ”´ Red = Error

---

## ğŸ”® Roadmap

### Completed (v5.0-5.6)

- [x] Unified launcher (singleton protection)
- [x] Orchestrator with regex + LLM routing
- [x] VRAM optimization (Qwen 3B brain)
- [x] Clean shutdown (process tree kill)
- [x] Right-click context menus on all icons
- [x] Auto-start agent handlers
- [x] Todo-it persistence
- [x] Test suite (13.5/14 pass)

### Next Up

- [ ] Auto-update status dots based on agent heartbeat
- [ ] Airweave integration (memory retrieval)
- [ ] NotebookLM integration (research)
- [ ] Multi-step workflow execution
- [ ] Visual MCP integration

---

## ğŸ› ï¸ Configuration

### settings.json

```json
{
  "ollama_url": "http://localhost:11434",
  "model": "gemma2:2b"
}
```

### Model Warmup

```powershell
python warm_models.py
# Loads gemma2:2b, qwen2.5:3b, moondream with keep_alive=-1
```

---

## ğŸ“ Key Design Decisions

1. **Regex-First Routing**: 95% of commands hit regex patterns (0ms latency)
2. **Two-Gear LLM Strategy**: Light router always resident, heavy brain on-demand
3. **File-Based IPC**: Simple, debuggable, no socket complexity
4. **Singleton Protection**: Lock files prevent zombie processes
5. **Local-First**: All processing happens on-device, no cloud dependencies

---

*Consider it handled.* ğŸ¯
